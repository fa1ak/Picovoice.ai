# Picovoice.ai

## Introduction
This repository contains my solutions for the Picovoice.ai coding screening test. Each solution is thoughtfully implemented in Python, thoroughly tested, and optimized for performance.

## üìù Table of Contents
- [Problem 1: Rain Probability](#problem-1-rain-probability)
- [Problem 2: Phoneme Word Mapping](#problem-2-phoneme-word-mapping)
- [Problem 3: Connectionist Temporal Classification (CTC) Loss](#problem-3-connectionist-temporal-classification-ctc-loss)
- [Assumptions & Edge Cases](#assumptions--edge-cases)
- [Installation & Usage](#installation--usage)
- [Personal Reflection](#personal-reflection)

---

## **Problem 1: Rain Probability**
**Goal**: Calculate the probability of rain on more than `n` days in Vancouver given daily probabilities.

### **Approach**
1. **Expected Rainy Days (`mu`)**: Compute the sum of probabilities across all 365 days.
2. **Variance (`sigma¬≤`)**: Calculate using `sum(p[i] * (1 - p[i]))`, as each day follows a Bernoulli distribution.
3. **Normal Approximation**: Approximate Poisson Binomial with a Normal Distribution `N(mu, sigma¬≤)`.
4. **Probability Calculation**: Use the **CDF** of the normal distribution to compute `P(X ‚â• n) = 1 - CDF(n)`.

### Challenges & Solutions:
- **Roadblock:** Floating-point precision issues when summing probabilities.
- **Fix:** Used `scipy.stats.norm` to handle large summations accurately.

### Complexity Analysis:
- **Time Complexity**: `O(N)` (linear scan)
- **Space Complexity**: `O(1)`

![Screenshot 2025-01-30 at 01 42 33](https://github.com/user-attachments/assets/e9f3c9fe-fb82-43e4-8bb0-9f805a7e71bc)

---

## **Problem 2: Phoneme Word Mapping**
**Goal**: Given a sequence of phonemes, find all possible words that match using a pronunciation dictionary.

### **Approach**
1. **Preprocess the Dictionary**: Convert the phoneme dictionary into a **hashmap** (`phoneme ‚Üí words`).
2. **Use Backtracking (DFS)**: Recursively match phoneme sequences with words.
3. **Return All Possible Sequences**: Store all valid combinations.

### Challenges & Solutions:
- **Roadblock:** Large dictionary leading to slow searches.
- **Fix:** Used a **Trie** structure instead of a raw dictionary.

### Complexity Analysis:
- **Preprocessing:** `O(W * L)`, where `W = words`, `L = avg. phoneme length`
- **Query Time:** `O(2^L)` in the worst case.

![Screenshot 2025-01-30 at 01 42 02](https://github.com/user-attachments/assets/419509a5-f921-40bd-8c58-f5b840259b41)

---

## **Problem 3: Connectionist Temporal Classification (CTC) Loss**
**Goal**: Implement CTC loss and backpropagation as per [Graves et al.](https://dl.acm.org/doi/abs/10.1145/1143844.1143891).

### **Approach**
1. **Input Validation & Preprocessing**
   - Introduced a `check_inputs` function to **validate input shapes and values**.
   - Implemented **`extend_targets`** to add blank labels between phonemes.
   
2. **Efficient Forward-Backward Computation**
   - **Forward Pass (`alpha` calculation)**
     - Used **log-space computations** to prevent numerical underflow.
     - Optimized with **vectorized NumPy operations** instead of nested loops.
   - **Backward Pass (`beta` calculation)**
     - Similar optimization using log-space operations.

3. **Batch Processing Support**
   - Implemented **batched forward and backward passes**.
   - Allowed **different reduction methods** (`mean`, `sum`, or `none`).

4. **Gradient Calculation**
   - Computed gradients using **log-add-exp trick** for numerical stability.
   - Ensured proper probability mass distribution.

5. **Error Handling & Robustness**
   - **Edge cases**: Short sequences, invalid dimensions, and incorrect target alignments.
   - Exception handling for **NaN or infinite values**.

### Challenges & Solutions:
- **Roadblock:** Initial implementation was **too slow**.
- **Fix:** Replaced nested loops with **vectorized NumPy operations**, reducing execution time **from seconds to milliseconds**.

### Performance Comparison:
| Version         | Execution Time |
|----------------|---------------|
| Initial Code   | 5.23 seconds  |
| Optimized Code | 0.0005 seconds |


<img width="574" alt="Screenshot 2025-01-30 at 22 21 48" src="https://github.com/user-attachments/assets/1e4d4e3e-74b8-49e5-986e-9bff9529059f" />


---

## **Assumptions & Edge Cases**
### Assumptions:
- For **Problem 1**, probabilities are **independent** for each day.
- For **Problem 2**, phoneme sequences are always **valid**.
- For **Problem 3**, CTC Loss assumes input sequences are sufficiently long to align with targets.

### Edge Cases Considered:
- **Rain Probability:** What if `n > 365`?  
- **Phoneme Matching:** What if a phoneme has no word match?  
- **CTC Loss:** Tested with `T >> L` to handle sequence mismatches.

---

## **Installation & Usage**
```bash
pip install -r requirements.txt
python src/rain_probability.py
python src/phoneme_word_mapping.py
python src/ctc_loss.py
```

---

## Personal Reflection
When I first received this challenge, it seemed quite daunting‚Äîfrom probability-based computations to phoneme mapping and complex CTC loss optimization. I knew that simply solving the problems wouldn't be enough‚ÄîI wanted to write efficient, scalable, and well-structured code while also demonstrating clear problem-solving skills.

One of the biggest challenges was ensuring numerical stability in probability calculations and optimizing execution time in CTC loss computation. Debugging segmentation faults and handling floating-point precision errors required a deep dive into performance optimization techniques, which was both challenging and rewarding.

I must admit that I found Question 3 (Shakespeare dataset) particularly challenging. I struggled with efficiently handling large text files in C and finding the most frequent words while maintaining memory efficiency. I would love to revisit that problem and refine my approach.

That said, I hope these solutions demonstrate my technical abilities, problem-solving mindset, and commitment to writing efficient code. I‚Äôd love the opportunity to join Picovoice, contribute to real-world AI challenges, and continue learning from an amazing team.

Thank you for considering my submission‚ÄîI look forward to the possibility of working together! 
